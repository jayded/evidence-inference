<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">27144385</article-id><article-id pub-id-type="pmc">4856346</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0153712</article-id><article-id pub-id-type="publisher-id">PONE-D-15-36885</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Communications</subject><subj-group><subject>Social Communication</subject><subj-group><subject>Social Media</subject><subj-group><subject>Twitter</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Network Analysis</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject><subj-group><subject>Twitter</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject><subj-group><subject>Twitter</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and Memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Bioassays and Physiological Analysis</subject><subj-group><subject>Electrophysiological Techniques</subject><subj-group><subject>Muscle Electrophysiology</subject><subj-group><subject>Electromyography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Dwell Time</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Dwell Time</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Communications</subject><subj-group><subject>Social Communication</subject><subj-group><subject>Social Media</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Network Analysis</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Negativity Bias in Media Multitasking: The Effects of Negative Social Media Messages on Attention to Television News Broadcasts</article-title><alt-title alt-title-type="running-head">Negativity Bias in Media Multitasking</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>K&#x000e4;tsyri</surname><given-names>Jari</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Kinnunen</surname><given-names>Teemu</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Kusumoto</surname><given-names>Kenta</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Oittinen</surname><given-names>Pirkko</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Ravaja</surname><given-names>Niklas</given-names></name><xref ref-type="aff" rid="aff002"><sup>2</sup></xref><xref ref-type="aff" rid="aff003"><sup>3</sup></xref><xref ref-type="aff" rid="aff004"><sup>4</sup></xref></contrib></contrib-group><aff id="aff001"><label>1</label><addr-line>Department of Computer Science, School of Science, Aalto University, Espoo, Finland</addr-line></aff><aff id="aff002"><label>2</label><addr-line>Department of Information and Service Economy, School of Business, Aalto University, Helsinki, Finland</addr-line></aff><aff id="aff003"><label>3</label><addr-line>Department of Social Research, University of Helsinki, Helsinki, Finland</addr-line></aff><aff id="aff004"><label>4</label><addr-line>Helsinki Institute for Information Technology, Aalto University, Helsinki, Finland</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Yechiam</surname><given-names>Eldad</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Technion Israel Institute of Technology, ISRAEL</addr-line></aff><author-notes><fn fn-type="conflict" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con" id="contrib001"><p>Conceived and designed the experiments: PO NR TK JK. Performed the experiments: KK JK. Analyzed the data: JK KK TK. Contributed reagents/materials/analysis tools: TK. Wrote the paper: JK PO NR TK KK.</p></fn><corresp id="cor001">* E-mail: <email>jari.katsyri@aalto.fi</email></corresp></author-notes><pub-date pub-type="epub"><day>4</day><month>5</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>11</volume><issue>5</issue><elocation-id>e0153712</elocation-id><history><date date-type="received"><day>21</day><month>8</month><year>2015</year></date><date date-type="accepted"><day>1</day><month>4</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; 2016 K&#x000e4;tsyri et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>K&#x000e4;tsyri et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0153712.pdf"/><abstract><p>Television viewers&#x02019; attention is increasingly more often divided between television and &#x0201c;second screens&#x0201d;, for example when viewing television broadcasts and following their related social media discussion on a tablet computer. The attentional costs of such multitasking may vary depending on the ebb and flow of the social media channel, such as its emotional contents. In the present study, we tested the hypothesis that negative social media messages would draw more attention than similar positive messages. Specifically, news broadcasts were presented in isolation and with simultaneous positive or negative Twitter messages on a tablet to 38 participants in a controlled experiment. Recognition memory, gaze tracking, cardiac responses, and self-reports were used as attentional indices. The presence of any tweets on the tablet decreased attention to the news broadcasts. As expected, negative tweets drew longer viewing times and elicited more attention to themselves than positive tweets. Negative tweets did not, however, decrease attention to the news broadcasts. Taken together, the present results demonstrate a negativity bias exists for social media messages in media multitasking; however, this effect does not amplify the overall detrimental effects of media multitasking.</p></abstract><funding-group><funding-statement>This study received financial support from the Finnish Funding Agency for Technology and Innovation (TEKES) as part of the NextMedia research programme (<ext-link ext-link-type="uri" xlink:href="http://www.nextmedia.fi">http://www.nextmedia.fi</ext-link>), initiated by Digile Ltd. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="4"/><table-count count="4"/><page-count count="21"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>In accordance with the guidelines of PLOS ONE concerning data availability, <xref ref-type="supplementary-material" rid="pone.0153712.s003">S3 Appendix</xref> contains all SPSS data analysis files for the experiment. To protect participants&#x02019; privacy, participant identifiers have been anonymized and no participant-related data are included in the data files.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>In accordance with the guidelines of PLOS ONE concerning data availability, <xref ref-type="supplementary-material" rid="pone.0153712.s003">S3 Appendix</xref> contains all SPSS data analysis files for the experiment. To protect participants&#x02019; privacy, participant identifiers have been anonymized and no participant-related data are included in the data files.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Television viewers are increasingly more often using secondary media devices such as tablets and mobile phones at the same time as viewing television [<xref rid="pone.0153712.ref001" ref-type="bibr">1</xref>,<xref rid="pone.0153712.ref002" ref-type="bibr">2</xref>]. Although these activities can be unrelated, tablets and mobile phones are also often used as &#x0201c;second screens&#x0201d; to complement the television viewing experience. For example, television viewers can take part in a shared viewing experience by following and commenting upon a social media stream such as Twitter [<xref rid="pone.0153712.ref003" ref-type="bibr">3</xref>] at the same time as viewing the broadcast [<xref rid="pone.0153712.ref004" ref-type="bibr">4</xref>]. Recent theoretical models have highlighted the role of both cognitive capacity limitations and motivational significance on the processing of mediated messages [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0153712.ref006" ref-type="bibr">6</xref>]. This gives reason to believe that simultaneous social media streams would decrease the allocation of cognitive resources to the television broadcasts, on the one hand, and that these detrimental effects would be amplified when the social media information is highly salient, on the other. In the present study, we investigate whether the affective tone of Twitter messages influences the viewers&#x02019; cognitive processing of simultaneously presented television news broadcasts. Our main prediction is that Twitter messages expressing negative attitudes will draw more attention and elicit more elaborate cognitive processing than similar positive Twitter messages.</p><sec id="sec002"><title>Negativity Effects</title><p>A unified finding from a diverse field of research ranging from financial decision making to person perception is that negative stimuli elicit greater affective, cognitive, and behavioral influences than equally intense positive stimuli [<xref rid="pone.0153712.ref007" ref-type="bibr">7</xref>&#x02013;<xref rid="pone.0153712.ref014" ref-type="bibr">14</xref>]. This effect can be explained by the different sensitivities (i.e., activation functions) of the appetitive and aversive motivational systems to positive and negative stimuli, respectively [<xref rid="pone.0153712.ref015" ref-type="bibr">15</xref>]: although appetitive activation is greater in a neutral environment (positivity offset), aversive activation increases more steeply for negative stimuli than appetitive activation does for positive stimuli (negativity bias).</p><p>Informational negativity effects, which refer to greater attention to and more detailed cognitive processing of negative than positive stimuli, have been distinguished from affective negativity effects [<xref rid="pone.0153712.ref012" ref-type="bibr">12</xref>,<xref rid="pone.0153712.ref013" ref-type="bibr">13</xref>]. A prime example of an informational negativity effect is that negative words elicit slower performance than positive words in a color-naming task even though the affective tone of words is entirely irrelevant for this task [<xref rid="pone.0153712.ref016" ref-type="bibr">16</xref>]. In the decision making framework, Yechiam and Hochman have theorized that losses (negative events) elicit more on-task attention than equivalent gains (positive events) even when wins and losses do not lead to asymmetries in subjective value [<xref rid="pone.0153712.ref017" ref-type="bibr">17</xref>]. Attention and emotions have also been explicitly considered in the context of mediated message processing. In particular, the Limited Capacity Model of Motivated Mediated Message Processing (&#x0201c;LC4MP&#x0201d;) [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0153712.ref006" ref-type="bibr">6</xref>] has combined elements from recent psychological theories on both attention and emotion. This model builds upon the assumption that individuals have a limited capacity for cognitive processing of information, and posits that a fixed pool of cognitive resources is divided continuously between information encoding, storage, and retrieval during mediated message processing. For the present purposes, we will focus on the encoding phase, which refers to the selection of information from sensory stores to the working memory. According to LC4MP model, resource allocation to encoding can be indexed by recognition memory performance [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>].</p><p>The original LC4MP model suggests that increasingly intense appetitive and aversive motivational activations both elicit increased resource allocation to encoding at first but that after an unspecified intensity threshold, aversive activation begins to shift resources away from encoding and towards action preparation [<xref rid="pone.0153712.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0153712.ref018" ref-type="bibr">18</xref>]. Because appetitive activation dominates in the absence of either positive or negative stimuli (i.e., positivity offset), weak positive media messages should be encoded better than weak negative media messages. Intermediate positive and negative messages should receive roughly equal encoding, and the encoding of strong positive messages should again surpass the encoding of strong negative messages. The prediction that negative messages should never receive more encoding resources than positive messages appears to be inconsistent with the known informational negativity effects and the loss attention model of Yechiam and Hochman. Furthermore, it could be speculated that the greater motivational activation elicited by negative than by equally intense positive stimuli (i.e., negativity bias) should also lead to greater allocation of cognitive resources to encoding at least at intermediate stimulus intensities. In fact, in a later development of the LC4MP model, it has been demonstrated that the recognition of moderately negative stimuli does surpass the recognition of moderately positive stimuli [<xref rid="pone.0153712.ref019" ref-type="bibr">19</xref>]. Similarly, some empirical studies have demonstrated better recognition memory for negative than for positive public service announcements [<xref rid="pone.0153712.ref020" ref-type="bibr">20</xref>] and for negative than for positive political advertisements [<xref rid="pone.0153712.ref021" ref-type="bibr">21</xref>].</p><p>In the present context, we expected that negative Twitter messages would elicit more attention than equally long and equally intense positive Twitter messages. Attention was indexed by participants&#x02019; own estimates, gaze tracking, and recognition memory. News broadcasts and tweets were presented on separate screens so that gaze dwell times (cumulative gaze fixation durations) could be used as a direct measure of visual attention. To summarize, we made the following predictions.</p><disp-quote><p><bold><italic>H1a-c</italic>:</bold> Negative tweets will elicit (a) higher self-reported attention, (b) longer gaze dwell times, and (c) better recognition memory than positive tweets.</p></disp-quote><p>The principle of negativity dominance suggests that combinations of positive and negative stimuli should elicit evaluations that are more negative than what would be expected on the basis of the individual negative and positive components [<xref rid="pone.0153712.ref013" ref-type="bibr">13</xref>]. In the present context, the effects of negativity dominance, if existent, would depend on the relative strengths of the news broadcasts and tweets. If news and tweets were roughly equally intense, negative tweets paired with positive news and positive tweets paired with negative tweets should elicit equally strong negative evaluations, and hence no interaction effects between news and tweet valences would follow. On the other hand, if the news were more intense than tweets, negative tweets should shift the evaluation of positive news towards negativity but have lesser or no effects on equally strong negative news. Finally, an opposite pattern could follow if tweets were more intense than news. The following research question was presented for exploring these effects.</p><disp-quote><p><bold><italic>RQ1a-b</italic>:</bold> Will tweet valence interact with news valence when predicting (a) emotional or (b) attentional responses to tweets (as measured by self-reports, recognition memory, and/or gaze dwell time)?</p></disp-quote></sec><sec id="sec003"><title>Media Multitasking</title><p>Psychological studies have demonstrated that people are limited in performing two stimulus-response tasks concurrently because cognitive resources required in such tasks can be utilized by only one task at a time (&#x0201c;bottleneck theories&#x0201d;) [<xref rid="pone.0153712.ref022" ref-type="bibr">22</xref>]. Cognitive resources that are critical in this sense include (at least) visual perceptual and declarative memory resources [<xref rid="pone.0153712.ref023" ref-type="bibr">23</xref>]. As discussed above, the LC4MP model [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0153712.ref006" ref-type="bibr">6</xref>] similarly holds that the attentional processing of mediated messages is limited by the fixed pool of cognitive resources. Both bottleneck theories and the LC4MP model predict that people can process only one visual media stream efficiently at a time.</p><p>Previous empirical studies have supported the debilitating effects of media multitasking on cognitive processing. For example, it has been shown that simultaneous text reading impairs recognition memory for television show excerpts [<xref rid="pone.0153712.ref024" ref-type="bibr">24</xref>], that simultaneous listening to an audio podcast impairs recognition and recall memory for an online news story [<xref rid="pone.0153712.ref025" ref-type="bibr">25</xref>], that textual news tickers impair recognition memory for television news broadcasts [<xref rid="pone.0153712.ref026" ref-type="bibr">26</xref>], and that television broadcasts impair recognition memory for textual stimuli [<xref rid="pone.0153712.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0153712.ref029" ref-type="bibr">29</xref>]. Previous studies have typically examined distractor tasks that have been irrelevant for the primary media task. In contrast, the attentional processing of two complementary media tasks could benefit from the semantic similarity between the tasks. For example, a previous study has demonstrated that audiovisual congruity improves the processing of television news broadcasts, plausibly because congruent auditory and visual channels can be processed as a unified semantic unit [<xref rid="pone.0153712.ref030" ref-type="bibr">30</xref>]. Similarly, Wang et al. [<xref rid="pone.0153712.ref031" ref-type="bibr">31</xref>] have postulated that task relevance is one of the main cognitive dimensions of media multitasking. They also demonstrated that relevant media multitasking is preferred over irrelevant media multitasking in daily choices; however, cognitive processing of unrelated and complementary multitasking was not explicitly compared. To our best knowledge, previous studies have not yet demonstrated that complementary media multitasking deteriorates the attentional processing of the primary media. Hence, we posed the following hypothesis.</p><disp-quote><p><bold><italic>H2a-b</italic>:</bold> News presented with tweets will elicit (a) lower self-reported attention and (b) poorer recognition memory than news presented without tweets.</p></disp-quote><p>The LC4MP model deposits that orienting responses elicited by stimulus novelty constitute one of the key mechanisms guiding attention during the encoding of mediated messages [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>]. Furthermore, the model considers heart rate (HR) deceleration&#x02014;or, equivalently, cardiac inter-beat intervals (IBI) lengthening&#x02014;as a reliable index of orienting responses (see also [<xref rid="pone.0153712.ref032" ref-type="bibr">32</xref>]). At first glance, the increased multitasking demands imposed by the simultaneous news broadcast viewing and Twitter feed reading could be expected to elicit a higher frequency of orienting responses and hence longer IBIs (HR deceleration). However, previous studies have demonstrated that moving pictures prompt longer IBIs than static pictures [<xref rid="pone.0153712.ref033" ref-type="bibr">33</xref>,<xref rid="pone.0153712.ref034" ref-type="bibr">34</xref>] and that events in television broadcasts also elicit cardiac decelerations [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0153712.ref006" ref-type="bibr">6</xref>]. Moving and professionally edited news broadcasts should be expected to trigger a higher frequency of orienting responses than textual Twitter messages. Hence, closer inspection suggests that directing attention away from news broadcasts to Twitter messages should decrease rather than increase orienting responses, which should consequently elicit weaker cardiac deceleration observable as shorter IBIs. That is,</p><disp-quote><p><bold><italic>H2c</italic>:</bold> News presented with tweets will elicit shorter cardiac IBIs than news presented without tweets.</p></disp-quote><p>We assumed that if negative tweets would draw more attention to themselves than positive tweets (H1), this increased attention would occur at the cost of attentional processing of news broadcasts. That is, we expected that news broadcasts presented with negative tweets would suffer from more pronounced attentional impairments than news broadcasts presented with positive tweets. Previous media studies without media multitasking have demonstrated greater orienting responses (longer cardiac IBIs) for negative than for positive radio advertisements [<xref rid="pone.0153712.ref035" ref-type="bibr">35</xref>] and for negative than for positive affective images [<xref rid="pone.0153712.ref036" ref-type="bibr">36</xref>]. In the present media multitasking context, we expected that orienting responses would be driven primarily by the television broadcasts (see above). This means that if negative Twitter messages would draw more attention away from the television broadcasts than positive Twitter messages, they should also elicit weaker cardiac orienting responses (shorter IBIs). To summarize, we made the following hypothesis.</p><disp-quote><p><bold><italic>H3a-c</italic>:</bold> News presented with negative tweets will elicit (a) lower self-reported attention, (b) poorer recognition memory, and (c) shorter IBIs than news presented with positive tweets.</p></disp-quote><p>A previous study has demonstrated that negative events (losses) in one task can enhance attention to a simultaneously performed secondary task (i.e., an attentional spillover effect) [<xref rid="pone.0153712.ref037" ref-type="bibr">37</xref>]. Although in the present experimental setup it was difficult for the participants to pay attention effectively to both screens (television and tablet) at the same time, we nevertheless cannot fully exclude this possibility. Hence, we note that a plausible alternative hypothesis to H3 is that negative as compared with positive tweets will elicit increased attention to the news broadcasts.</p></sec></sec><sec sec-type="materials|methods" id="sec004"><title>Materials and Methods</title><sec id="sec005"><title>Participants</title><p>Participants were 38 Finnish under- or post-graduate university students (27 male and 11 female; <italic>M</italic> = 25.1 years, <italic>SD</italic> = 4.9 years). All participants were native Finnish speakers, and they reported normal hearing and normal or corrected-to-normal vision. Participants received three movie tickets in compensation for their participation. Gaze tracking data were recorded from a subset of 17 participants (12 male and 5 female; <italic>M</italic> = 25.1 years, <italic>SD</italic> = 2.7 years).</p></sec><sec id="sec006"><title>Ethics Statement</title><p>Written consent was obtained from all participants. Our data collection and reporting comply with the Finnish Advisory Board on Research Integrity (TENK) guidelines for human-subject research [<xref rid="pone.0153712.ref038" ref-type="bibr">38</xref>]. Because the present research was non-medical, requirement for prior ethical approval was waived by the Aalto University Research Ethics Committee.</p></sec><sec id="sec007"><title>Design</title><p>The experiment used a 2 &#x000d7; 3 &#x000d7; 4 within-subjects design with News Valence (positive, negative), Tweet Condition (positive, negative, control [none]), and Mood (joyful, relaxed, depressed, and fearful) as within-subjects factors. Results for the mood condition, which failed to elicit any significant effects on attention, are available in <xref ref-type="supplementary-material" rid="pone.0153712.s001">S1 Appendix</xref>. To counterbalance the assignment of news to the 12 conditions (3 tweet &#x000d7; 4 mood conditions), a 12 &#x000d7; 12 Latin square [<xref rid="pone.0153712.ref039" ref-type="bibr">39</xref>] was used. The same Latin square was replicated for the 12 positive and 12 negative news.</p></sec><sec id="sec008"><title>Stimuli</title><sec id="sec009"><title>News videos</title><p>The news stimuli were 24 news video clips. For the preselection, 12 additional participants rated the valence and arousal (both on 9-point scales; see Section Self-report Measures) of 32 news videos selected from regional news broadcasts produced by the Finnish Broadcasting Company [<xref rid="pone.0153712.ref040" ref-type="bibr">40</xref>]. Valence pre-ratings were used to select the 12 most positive (e.g., &#x0201c;Record-breaking salmon summer to be expected on the Tornio River&#x0201d;) and the 12 most negative news videos (e.g., &#x0201c;Hamina struggles with a crippling debt&#x0201d;). Positive and negative news videos received clearly different valence pre-ratings, <italic>M</italic>s = 6.3 and 3.5 (<italic>SD</italic>s = 0.4 and 0.6), <italic>F</italic>(1, 11) = 101.11, <italic>p</italic> &#x0003c; 0.001, <italic>&#x003b7;</italic><sup><italic>2</italic></sup> = 0.74, but similar arousal pre-ratings, <italic>M</italic>s = 3.7 and 3.8 (<italic>SD</italic>s = 1.4), <italic>F</italic>(1, 11) &#x0003c; 1, <italic>&#x003b7;</italic><sup><italic>2</italic></sup> = 0.00. The mean video duration for both positive and negative news was 42 s (range 31 to 54 s).</p></sec><sec id="sec010"><title>Tweets</title><p>Four positive and four negative fictional but plausible tweets were created for each news video (in total, 192 tweets). Positivity and negativity were defined as the writer&#x02019;s attitude towards the topic of the news (e.g., for a debt-related news video, positive message: &#x0201c;A debt crisis is an opportunity for something new&#x0201d; and negative message: &#x0201c;Unbelievable. Keep your debts. I&#x02019;m moving out&#x0201d;). An initial set of tweets was created by asking each of the 12 pretest participants to write one positive and one negative comment on each news topic. A subset of 192 tweets was then selected and edited, and a panel of three judges classified these tweets as positive or negative. Twelve tweets without a full consensus were rewritten. The average lengths of positive and negative tweets were 67 and 71 characters, <italic>F</italic>(1, 22) = 2.06, <italic>p</italic> = 0.17, <italic>&#x003b7;</italic><sup><italic>2</italic></sup> = 0.08. Thirteen additional participants were assigned randomly to two groups, which saw separate halves of the tweets, and were then asked to evaluate the attitude of each tweet on a scale ranging from 1 (extremely negative) to 9 (extremely positive). Attitude evaluations for positive and negative tweets were clearly differentiated, <italic>M</italic>s = 7.1 and 2.8 (<italic>SD</italic>s = 0.3 and 0.4), <italic>F</italic>(1, 11) = 627.12, <italic>p</italic> &#x0003c; 0.001, <italic>&#x003b7;</italic><sup><italic>2</italic></sup> = 0.92. Importantly, positive and negative tweets were also equally intense as measured with distances from the scale middle (i.e., the absolute value of attitude rating minus 5), <italic>M</italic> = 2.4 (<italic>SD</italic> = 0.4) for both.</p></sec></sec><sec id="sec011"><title>Procedure</title><p><xref ref-type="fig" rid="pone.0153712.g001">Fig 1</xref> shows the experimental setup from a participant&#x02019;s perspective. After a brief description of the experiment, the participant filled out background questionnaires. Electrodes were then attached and the participant was seated in a comfortable armchair, followed by a rest period of 5 min for the baseline measurements. Participants were instructed that they would be viewing a number of news videos on the television, some of which would be accompanied by tweets on the tablet, and that they should attempt to memorize the contents of both news and tweets.</p><fig id="pone.0153712.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.g001</object-id><label>Fig 1</label><caption><title>Snapshot of the experimental setup from a participant&#x02019;s first-person view.</title></caption><graphic xlink:href="pone.0153712.g001"/></fig><p>Experimental procedure was practiced with one video that was not included in the actual stimuli. During the actual experiment, 24 trials were presented in a randomized order. During each trial, the participant initiated the news video playback by pressing a button on the tablet. The four tweets for each news video, when present, were shown in a random order and at random points of time; however, at least 10 s after the video onset, at most 5 s before the video offset, and with at least 5 s intervals in between. To create a closer resemblance to real Twitter messages, each tweet was presented with a profile image, name, and nickname of its fictional writer. Profile images depicted emotionally neutral faces, user names and nicknames were formed on the basis of common Finnish first and last names, and male and female identities were counterbalanced across messages. When tweets were absent, the tablet remained blank throughout the trial. After each news video, a white fixation cross was presented for 3 s in the center of the television on a medium gray background, after which the participants filled the self-report questionnaires for the trial. After viewing all news videos, the electrodes were removed and the participant completed memory tasks. The participant was then debriefed, and thanked for his or her participation.</p><p>News videos were displayed on a 40-inch (88.6 &#x000d7; 49.8 cm or 22.2 &#x000d7; 12.6 degrees of visual angle) Sony Bravia KDL-40HX800 television, which was positioned at a distance of 225 cm from the participant (as per recommendation [<xref rid="pone.0153712.ref041" ref-type="bibr">41</xref>]). News videos were displayed at a spatial resolution of 1024 &#x000d7; 576 pixels and a temporal resolution of 25 frames per second. Sound playback was delivered via closed headphones. Twitter messages were displayed on a 10.1-inch (21.7 &#x000d7; 13.6 cm or 24.5 &#x000d7; 15.5 degrees) Samsung Galaxy Tab tablet positioned on a mount attached to the table in front of the participant, at an approximate distance of 50 cm.</p></sec><sec id="sec012"><title>Self-report Measures</title><sec id="sec013"><title>Emotional reactions</title><p>Participants rated their emotional reactions to news videos (when tweets were not present) or the combinations of news videos and tweets in terms of emotional valence and arousal using 9-point pictorial scales similar to the Self-Assessment Manikin (SAM; [<xref rid="pone.0153712.ref042" ref-type="bibr">42</xref>]). The scales ranged from 1 (very negative or unpleasant) to 9 (very positive or pleasant) for emotional valence, and from 1 (low visceral agitation) to 9 (high visceral agitation) for emotional arousal.</p></sec><sec id="sec014"><title>Gaze allocation and attention</title><p>Participants were asked to give their own estimates of their gaze allocation between the television (news broadcasts) and the tablet (tweets) on a scale ranging from 1 (watched only television) to 4 (watched television and tablet equally) to 7 (watched only tablet). Participants were also asked to evaluate their attention to news and tweets separately using two items: &#x0201c;I attended the news/tweets&#x0201d; and &#x0201c;I was engrossed in the news/tweets&#x0201d; (Cronbachs&#x02019; &#x003b1; = 0.84 for both news and tweets). These evaluations were made on a scale ranging from 1 (completely disagree) to 7 (completely agree).</p></sec><sec id="sec015"><title>Excluded items</title><p>Additional media experience self-report items were collected (<xref ref-type="supplementary-material" rid="pone.0153712.s001">S1 Appendix</xref>) but excluded from the present analysis as irrelevant for the present hypotheses.</p></sec></sec><sec id="sec016"><title>Behavioral Measures</title><sec id="sec017"><title>Gaze tracking</title><p>We used wearable SMI Eye-tracking Glasses (SensoMotoric Instruments GmbH, Teltow, Germany) for gaze position tracking to allow free head movements while switching gaze between the displays. Calibration was done on the television screen using a 3-point calibration procedure provided by the manufacturer, and its success was tested using a custom application that presented a fixation cross sequentially on screen corners in a random order. Due to the limitations of the wearable eye-tracking glasses, gaze tracking data could not be obtained from 7 participants with eye glasses. In addition, calibration test results were unsatisfactory for 14 other participants, which left data from 17 participants for analysis. Gaze data were recorded at 30 Hz temporal resolution. Gaze fixations were detected by the manufacturer&#x02019;s software, overlain on videos recorded from the participants&#x02019; first-person view, and classified manually as falling on television or tablet. Gaze dwell time on the tablet was then calculated for each trial by dividing the cumulative gaze fixation duration on tablet by the sum of the cumulative gaze fixation durations on tablet and television.</p></sec><sec id="sec018"><title>Recognition Memory</title><p>Factual recognition memory for news videos was tested using a knowledge acquisition task (cf. [<xref rid="pone.0153712.ref043" ref-type="bibr">43</xref>,<xref rid="pone.0153712.ref044" ref-type="bibr">44</xref>]). Three questions focusing on central factual details were generated for each news video (e.g., &#x0201c;How large was the debt burden of per resident?&#x0201d;). One correct and three incorrect but plausible response options were given for each question (e.g., 2,500 &#x020ac;; 3,400 &#x020ac;; 4,500 &#x020ac;; and 5,500 &#x020ac;). Recognition memory for tweets was tested by asking each participant to select the four tweet messages that he or she had read for each news video. Twelve options, six positive and six negative, were given for each news video: four target messages with the correct emotional valence (either positive or negative), two foil messages with the same valence, and six foil messages with the opposite valence.</p><p>Although the factual recognition memory task has been routinely used to index low-level stimulus encoding [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>], we were concerned that the encoding and retrieval of factual items would also depend on higher-level cognitive processing (e.g., associative learning). Consequently, we also included a visual recognition memory task as a more direct index of visual encoding. Visual recognition was tested with a set of 144 images, which consisted of three target images taken from each of the present 24 news videos and three foil images taken from 24 other news videos. Participants saw these images after the actual experiment in a random order and were asked to indicate whether they had seen each image during the experiment. All recognition memory scores were scaled to proportional values between 0 and 1.</p></sec></sec><sec id="sec019"><title>Physiological Measures</title><p>Psychophysiological data were recorded with Varioport portable recorder system (Becker Meditec, Karslruhe, Germany) at a resolution of 1 kHz and preprocessed in Matlab (MathWorks Inc., Natick, MA). In addition to cardiac measurements which were used to index attention, we also used facial muscle activation and skin conductance measurements to ensure that our stimuli elicited intended emotional responses in terms of valence and arousal [<xref rid="pone.0153712.ref036" ref-type="bibr">36</xref>], respectively. For each physiological signal, mean values were calculated for each of the full 5-s epochs during news video viewing.</p><sec id="sec020"><title>Cardiac responses</title><p>Electrocardiography signal was recorded using three Ag/AgCl electrodes, pre-filled with hydrogel (model F-55; Skintact, Innsbruck, Austria), and positioned on the chest in a modified Lead III placement. R-peaks were detected from ECG signal using AuBT toolbox [<xref rid="pone.0153712.ref045" ref-type="bibr">45</xref>]. Interbeat-intervals (IBIs) were derived from the R peaks and resampled into equal time intervals every 100 ms. Physiologically unrealistic IBI values (beyond 400&#x02013;1500 ms, or deviating more than 3 SDs from the participant&#x02019;s mean) were removed and replaced using cubic spline interpolation. Physiological IBI data from one participant with abnormally high signal variance during the baseline measurement (more than 3 SDs above the mean value of all participants) were removed.</p></sec><sec id="sec021"><title>Facial muscle responses</title><p>Facial electromyography (EMG) activities were recorded from the left <italic>zygomaticus major</italic> (&#x0201c;smiling muscle&#x0201d; on the cheek; ZM), <italic>corrugator supercilii</italic> (&#x0201c;frowning muscle&#x0201d; pulling the eyebrows down diagonally; CS), and <italic>orbicularis oculi</italic> (&#x0201c;crows&#x02019; feet wrinkle muscle&#x0201d; orbiting the eye; OO) muscle regions [<xref rid="pone.0153712.ref046" ref-type="bibr">46</xref>] using surface Ag/AgCl electrodes with a contact area of 4 mm diameter (Med Associates Incorporated, St. Albans, VT). Electrodes were filled with electrode gel (model TD-240; Med Assoc. Inc.). Raw EMG data was band-pass filtered (20&#x02013;500 Hz), band-stop filtered (49&#x02013;51 Hz), and rectified before mean value extraction. Physiological data from participants with abnormally high signal variance during the baseline measurements (more than 3 SDs above the group&#x02019;s mean) were removed, resulting in the removal of ZM data from one participant and OO data from another participant. Log transformations were used to reduce positive skew in the EMG data.</p></sec><sec id="sec022"><title>Skin conductance responses</title><p>Electrodermal activity (EDA) signal was recorded by applying a constant voltage of 0.5 V across Ag/AgCl electrodes with a contact area of 4 mm diameter. Electrodes were filled with skin conductance electrode paste (TD-246) and attached to the middle phalanges of the index and little fingers of the participant&#x02019;s non-dominant hand after hands had been washed with soap and water. EDA signal was downsampled to 10 Hz, smoothed with an adaptive filter, and divided into phasic and tonic components using Ledalab toolbox (version 3.4.4; [<xref rid="pone.0153712.ref047" ref-type="bibr">47</xref>]). Integrated skin conductance responses (iSCRs) were then extracted from the phasic signals as recommended in Benedek and Kaernbach [<xref rid="pone.0153712.ref047" ref-type="bibr">47</xref>]. Physiological iSCR data from one participant with abnormally high signal variance during the baseline measurement (more than 3 SDs above the mean value of all participants) were removed. Log-transformation was used to reduce positive skew in the iSCR data.</p></sec></sec><sec id="sec023"><title>Data Analysis</title><p>Because the consecutive physiological measurements were not independent from each other and their number varied depending on the news videos of varying lengths, a conventional variance analysis (ANOVA) would have been inappropriate for the present data. Instead, we opted to use Linear Mixed Model (LMM) analysis, which is an extension of ANOVA analysis that is capable of accounting for both of these problems (for tutorials, see [<xref rid="pone.0153712.ref048" ref-type="bibr">48</xref>&#x02013;<xref rid="pone.0153712.ref050" ref-type="bibr">50</xref>]). The LMM analysis also allowed us to correctly specify both participants and news stimuli as randomly sampled variables [<xref rid="pone.0153712.ref051" ref-type="bibr">51</xref>]. We used LMM procedure with restricted maximum-likelihood estimation in SPSS (version 22). For specification and explanation of the LMM equations, see <xref ref-type="supplementary-material" rid="pone.0153712.s002">S2 Appendix</xref>.</p><p>All analyses included news valence, tweet condition, and interaction between news valence and tweet condition as fixed factors. Mood condition, which exerted non-significant effects for most variables, was included only for emotional self-reports (SAM valence and arousal) and physiological measurements (facial EMG at ZM, CS, and OO locations; and iSCR). To account for the within-subjects model, random intercepts were always included for participants. Random intercepts for news stimuli (cf. [<xref rid="pone.0153712.ref051" ref-type="bibr">51</xref>]) and random slopes for the fixed factors were also included when they were estimable and at least marginally significant (<italic>p</italic> &#x0003c; 0.20).</p><p>For physiological measures, measurement epoch and baseline activity level (both continuous) were included as additional fixed factors, and random slopes for epochs were additionally included to the random part. To account for the non-independence of measurements, epoch was defined as the repeated variable for participants and news videos, and a first-order autoregressive model (AR1) was specified as the error variance-covariance matrix.</p><p>Statistical significance level was set to <italic>p</italic> &#x0003c; 0.05 (two-tailed) for all tests. Correction for multiple comparisons was not applied for statistical tests that were planned in advance (i.e., for hypotheses H1 to H3 and RQ1). When applicable, the following planned contrasts were used as follow-up tests for significant effects: &#x0201c;negative &#x0003e; positive tweets&#x0201d;, &#x0201c;no tweets &#x0003e; positive + negative tweets&#x0201d;, and &#x0201c;(negative &#x0003e; positive tweets) &#x000d7; (negative &#x0003e; positive news videos)&#x0201d;.</p></sec></sec><sec sec-type="results" id="sec024"><title>Results</title><sec id="sec025"><title>Emotional Responses</title><p>Mean values for all dependent variables by news valence and tweet conditions are available in <xref ref-type="table" rid="pone.0153712.t001">Table 1</xref>. <xref ref-type="table" rid="pone.0153712.t002">Table 2</xref> shows statistical analysis results for emotional response variables. Consistently with our pretest, positive news videos elicited more pleasant SAM valence ratings than negative news videos, 95% CI for the difference [2.19, 2.89] points on the 9-step scale. Consistently with previous facial EMG studies [<xref rid="pone.0153712.ref052" ref-type="bibr">52</xref>], positive news elicited greater ZM and OO activations and weaker CS activations than negative news, 95% CIs [0.03, 0.06], [0.04, 0.09], and [&#x02013;0.07, &#x02013;0.12] log(&#x003bc;V) units, respectively.</p><table-wrap id="pone.0153712.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.t001</object-id><label>Table 1</label><caption><title>Mean results (with SEs) by the interaction between news and tweet valences.</title></caption><alternatives><graphic id="pone.0153712.t001g" xlink:href="pone.0153712.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/><th align="center" colspan="3" rowspan="1">Negative news</th><th align="center" colspan="3" rowspan="1">Positive news</th></tr><tr><th align="left" rowspan="1" colspan="1">Variable type</th><th align="left" rowspan="1" colspan="1">Variable</th><th align="center" rowspan="1" colspan="1">Neg. tweets</th><th align="center" rowspan="1" colspan="1">Pos. tweets</th><th align="center" rowspan="1" colspan="1">No tweets</th><th align="center" rowspan="1" colspan="1">Neg. tweets</th><th align="center" rowspan="1" colspan="1">Pos. tweets</th><th align="center" rowspan="1" colspan="1">No tweets</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Self-report</td><td align="left" rowspan="1" colspan="1">SAM Valence</td><td align="center" rowspan="1" colspan="1">3.78 (0.14)</td><td align="center" rowspan="1" colspan="1">3.75 (0.14)</td><td align="center" rowspan="1" colspan="1">3.63 (0.14)</td><td align="center" rowspan="1" colspan="1">5.88 (0.14)</td><td align="center" rowspan="1" colspan="1">6.45 (0.14)</td><td align="center" rowspan="1" colspan="1">6.45 (0.14)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">SAM Arousal</td><td align="center" rowspan="1" colspan="1">4.45 (0.23)</td><td align="center" rowspan="1" colspan="1">4.35 (0.23)</td><td align="center" rowspan="1" colspan="1">4.33 (0.23)</td><td align="center" rowspan="1" colspan="1">4.00 (0.23)</td><td align="center" rowspan="1" colspan="1">4.10 (0.23)</td><td align="center" rowspan="1" colspan="1">4.23 (0.23)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Gaze on Tablet</td><td align="center" rowspan="1" colspan="1">3.66 (0.23)</td><td align="center" rowspan="1" colspan="1">3.53 (0.23)</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">3.82 (0.23)</td><td align="center" rowspan="1" colspan="1">3.30 (0.23)</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Attention</td><td align="center" rowspan="1" colspan="1">3.11 (0.23)</td><td align="center" rowspan="1" colspan="1">2.93 (0.23)</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">3.19 (0.23)</td><td align="center" rowspan="1" colspan="1">2.82 (0.23)</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Attention</td><td align="center" rowspan="1" colspan="1">4.15 (0.17)</td><td align="center" rowspan="1" colspan="1">4.22 (0.17)</td><td align="center" rowspan="1" colspan="1">4.55 (0.17)</td><td align="center" rowspan="1" colspan="1">3.83 (0.17)</td><td align="center" rowspan="1" colspan="1">4.18 (0.17)</td><td align="center" rowspan="1" colspan="1">4.46 (0.17)</td></tr><tr><td align="left" rowspan="1" colspan="1">Behavior</td><td align="left" rowspan="1" colspan="1">Gaze Dwell Time</td><td align="center" rowspan="1" colspan="1">29% (23%)</td><td align="center" rowspan="1" colspan="1">28% (23%)</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">33% (23%)</td><td align="center" rowspan="1" colspan="1">26% (23%)</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Recognition</td><td align="center" rowspan="1" colspan="1">83% (23%)</td><td align="center" rowspan="1" colspan="1">77% (23%)</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">82% (23%)</td><td align="center" rowspan="1" colspan="1">78% (23%)</td><td align="center" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Recognition (Factual)</td><td align="center" rowspan="1" colspan="1">58% (5%)</td><td align="center" rowspan="1" colspan="1">53% (5%)</td><td align="center" rowspan="1" colspan="1">59% (5%)</td><td align="center" rowspan="1" colspan="1">49% (5%)</td><td align="center" rowspan="1" colspan="1">52% (5%)</td><td align="center" rowspan="1" colspan="1">63% (5%)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Recognition (Visual)</td><td align="center" rowspan="1" colspan="1">71% (4%)</td><td align="center" rowspan="1" colspan="1">67% (4%)</td><td align="center" rowspan="1" colspan="1">78% (4%)</td><td align="center" rowspan="1" colspan="1">79% (4%)</td><td align="center" rowspan="1" colspan="1">78% (4%)</td><td align="center" rowspan="1" colspan="1">88% (4%)</td></tr><tr><td align="left" rowspan="1" colspan="1">Physiology</td><td align="left" rowspan="1" colspan="1">EMG-ZM</td><td align="center" rowspan="1" colspan="1">0.97 (0.03)</td><td align="center" rowspan="1" colspan="1">0.96 (0.03)</td><td align="center" rowspan="1" colspan="1">0.96 (0.03)</td><td align="center" rowspan="1" colspan="1">0.99 (0.03)</td><td align="center" rowspan="1" colspan="1">0.99 (0.03)</td><td align="center" rowspan="1" colspan="1">1.03 (0.03)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EMG-CS</td><td align="center" rowspan="1" colspan="1">1.62 (0.05)</td><td align="center" rowspan="1" colspan="1">1.60 (0.05)</td><td align="center" rowspan="1" colspan="1">1.64 (0.05)</td><td align="center" rowspan="1" colspan="1">1.52 (0.05)</td><td align="center" rowspan="1" colspan="1">1.52 (0.05)</td><td align="center" rowspan="1" colspan="1">1.52 (0.05)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EMG-OO</td><td align="center" rowspan="1" colspan="1">0.96 (0.03)</td><td align="center" rowspan="1" colspan="1">0.95 (0.03)</td><td align="center" rowspan="1" colspan="1">0.94 (0.03)</td><td align="center" rowspan="1" colspan="1">1.01 (0.03)</td><td align="center" rowspan="1" colspan="1">1.01 (0.03)</td><td align="center" rowspan="1" colspan="1">1.03 (0.03)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">iSCR</td><td align="center" rowspan="1" colspan="1">0.19 (0.02)</td><td align="center" rowspan="1" colspan="1">0.20 (0.02)</td><td align="center" rowspan="1" colspan="1">0.18 (0.02)</td><td align="center" rowspan="1" colspan="1">0.20 (0.02)</td><td align="center" rowspan="1" colspan="1">0.18 (0.02)</td><td align="center" rowspan="1" colspan="1">0.18 (0.02)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Cardiac IBI</td><td align="center" rowspan="1" colspan="1">852 (7)</td><td align="center" rowspan="1" colspan="1">847 (7)</td><td align="center" rowspan="1" colspan="1">855 (7)</td><td align="center" rowspan="1" colspan="1">854 (7)</td><td align="center" rowspan="1" colspan="1">855 (7)</td><td align="center" rowspan="1" colspan="1">859 (7)</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p>SAM valence and arousal were recorded on a 1&#x02013;9 scale and other self-ratings on a 1&#x02013;7 scale. Recognition memory results and tracked gaze allocations on tablet were recorded as proportional values. For SAM valence, higher values denote higher pleasantness. For gaze dwell time, higher values denote more attention on tablet. Physiological measurements were recorded in ln(&#x003bc;V) units for EMG, ln(&#x003bc;S) units for iSCR, and ms units for IBI. SAM = self-assessment manikin; EMG = facial electromyography; ZM = <italic>zygomaticus major</italic> muscle; CS = <italic>corrugator supercilii</italic> muscle; OO = <italic>orbicularis oculi</italic> muscle; IBI = inter-beat interval; iSCR = integrated skin conductance response.</p></fn></table-wrap-foot></table-wrap><table-wrap id="pone.0153712.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.t002</object-id><label>Table 2</label><caption><title>LMM analysis results for emotional measures.</title></caption><alternatives><graphic id="pone.0153712.t002g" xlink:href="pone.0153712.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Variable</th><th align="left" rowspan="1" colspan="1">Effect</th><th align="center" rowspan="1" colspan="1">df<xref ref-type="table-fn" rid="t002fn002"><sup>a</sup></xref></th><th align="center" rowspan="1" colspan="1"><italic>F</italic></th><th align="center" rowspan="1" colspan="1"><italic>p</italic></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">SAM Valence</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 22<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">224.05</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 846</td><td align="char" char="." rowspan="1" colspan="1">4.95</td><td align="char" char="." rowspan="1" colspan="1">0.007 <xref ref-type="table-fn" rid="t002fn006">**</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 846</td><td align="char" char="." rowspan="1" colspan="1">9.26</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Mood</td><td align="center" rowspan="1" colspan="1">3, 844</td><td align="char" char="." rowspan="1" colspan="1">8.04</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">SAM Arousal</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 22<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">1.86</td><td align="char" char="." rowspan="1" colspan="1">0.187</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 846</td><td align="char" char="." rowspan="1" colspan="1">0.16</td><td align="char" char="." rowspan="1" colspan="1">0.851</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 846</td><td align="char" char="." rowspan="1" colspan="1">1.32</td><td align="char" char="." rowspan="1" colspan="1">0.268</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Mood</td><td align="center" rowspan="1" colspan="1">3, 844</td><td align="char" char="." rowspan="1" colspan="1">1.29</td><td align="char" char="." rowspan="1" colspan="1">0.277</td></tr><tr><td align="left" rowspan="1" colspan="1">Facial EMG-ZM</td><td align="left" rowspan="1" colspan="1">Baseline</td><td align="center" rowspan="1" colspan="1">1, 34</td><td align="char" char="." rowspan="1" colspan="1">43.87</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Epoch</td><td align="center" rowspan="1" colspan="1">1, 36<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">28.99</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 1206</td><td align="char" char="." rowspan="1" colspan="1">22.62</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 72<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">1.05</td><td align="char" char="." rowspan="1" colspan="1">0.354</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1207</td><td align="char" char="." rowspan="1" colspan="1">1.95</td><td align="char" char="." rowspan="1" colspan="1">0.143</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Mood</td><td align="center" rowspan="1" colspan="1">3, 108<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">19.16</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Facial EMG-CS</td><td align="left" rowspan="1" colspan="1">Baseline</td><td align="center" rowspan="1" colspan="1">1, 36</td><td align="char" char="." rowspan="1" colspan="1">44.33</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Epoch</td><td align="center" rowspan="1" colspan="1">1, 37<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">5.84</td><td align="char" char="." rowspan="1" colspan="1">0.021 <xref ref-type="table-fn" rid="t002fn005">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 1004</td><td align="char" char="." rowspan="1" colspan="1">56.49</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1004</td><td align="char" char="." rowspan="1" colspan="1">0.75</td><td align="char" char="." rowspan="1" colspan="1">0.471</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1005</td><td align="char" char="." rowspan="1" colspan="1">0.90</td><td align="char" char="." rowspan="1" colspan="1">0.409</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Mood</td><td align="center" rowspan="1" colspan="1">3, 111<xref ref-type="table-fn" rid="t002fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">12.59</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Facial EMG-OO</td><td align="left" rowspan="1" colspan="1">Baseline</td><td align="center" rowspan="1" colspan="1">1, 35</td><td align="char" char="." rowspan="1" colspan="1">6.52</td><td align="char" char="." rowspan="1" colspan="1">0.015 <xref ref-type="table-fn" rid="t002fn005">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Epoch</td><td align="center" rowspan="1" colspan="1">1, 37<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">14.69</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 36<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">28.00</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1114</td><td align="char" char="." rowspan="1" colspan="1">0.20</td><td align="char" char="." rowspan="1" colspan="1">0.822</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1115</td><td align="char" char="." rowspan="1" colspan="1">1.72</td><td align="char" char="." rowspan="1" colspan="1">0.180</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Mood</td><td align="center" rowspan="1" colspan="1">3, 108<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">24.80</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">iSCR</td><td align="left" rowspan="1" colspan="1">Baseline</td><td align="center" rowspan="1" colspan="1">1, 31</td><td align="char" char="." rowspan="1" colspan="1">13.75</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Epoch</td><td align="center" rowspan="1" colspan="1">1, 34<xref ref-type="table-fn" rid="t002fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">115.53</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t002fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 1687</td><td align="char" char="." rowspan="1" colspan="1">0.36</td><td align="char" char="." rowspan="1" colspan="1">0.551</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1688</td><td align="char" char="." rowspan="1" colspan="1">1.23</td><td align="char" char="." rowspan="1" colspan="1">0.292</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1689</td><td align="char" char="." rowspan="1" colspan="1">0.97</td><td align="char" char="." rowspan="1" colspan="1">0.378</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Mood</td><td align="center" rowspan="1" colspan="1">3, 1688</td><td align="char" char="." rowspan="1" colspan="1">0.96</td><td align="char" char="." rowspan="1" colspan="1">0.411</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t002fn001"><p>SAM = self-assessment manikin; IBI = inter-beat interval; iSCR = integrated skin conductance response; EMG = facial electromyography; ZM = <italic>zygomaticus major</italic> muscle; CS = <italic>corrugator supercilii</italic> muscle; OO = <italic>orbicularis oculi</italic> muscle.</p></fn><fn id="t002fn002"><p><sup>a</sup>Welch-Sattertwaite approximation (rounded to the closest integer). Note that degrees of freedom for the error term depend on the included random variables.</p></fn><fn id="t002fn003"><p><sup>b</sup>The model included random intercepts for news stimuli.</p></fn><fn id="t002fn004"><p><sup>c</sup>The model included random slopes for this term across participants.</p></fn><fn id="t002fn005"><p>*<italic>p</italic> &#x0003c; 0.05.</p></fn><fn id="t002fn006"><p>**<italic>p</italic> &#x0003c; 0.01.</p></fn><fn id="t002fn007"><p>***<italic>p</italic> &#x0003c; 0.001</p></fn></table-wrap-foot></table-wrap><p>The main effect of tweet condition on SAM pleasantness ratings was significant; however, this main effect was qualified by a significant interaction between tweet condition and news valence (<xref ref-type="table" rid="pone.0153712.t002">Table 2</xref>). Planned contrast test indicated significant interaction between news and tweet valences (<italic>p</italic> &#x0003c; 0.001). Specifically, participants gave more negative ratings for negative than for positive tweets that were paired with positive news videos (<italic>p</italic> &#x0003c; 0.001), 95% CI [&#x02013;0.32, &#x02013;0.82]. In contrast, the effects of negative and positive tweets did not differ when paired with negative news, 95% CI [&#x02013;0.22, 0.28]. These findings answer our research question RQ1a by demonstrating that negative tweets are emotionally more effective when paired with positive news videos. The effect of negative tweets was much smaller than the effect of negative news (about one tenth; see 95% CIs above). Surprisingly, the main effect of tweet condition and the interaction effect between news valence and tweet condition were both non-significant for all facial EMG responses (<xref ref-type="table" rid="pone.0153712.t002">Table 2</xref>).</p><p>No significant effects were observed for SAM arousal ratings (<xref ref-type="table" rid="pone.0153712.t002">Table 2</xref>). In particular, the main effect of tweet condition was non-significant, which suggests that reading tweets simultaneously while watching news did not evoke elevated arousal. Consistently, the effect of tweet condition on physiological arousal (iSCR) was also non-significant (<xref ref-type="table" rid="pone.0153712.t002">Table 2</xref>).</p></sec><sec id="sec026"><title>Attention to Tweets</title><p>Statistical analysis results for tweet-related attentional measures are shown in <xref ref-type="table" rid="pone.0153712.t003">Table 3</xref>, and tweet-related attentional results for negative and positive tweets are illustrated in <xref ref-type="fig" rid="pone.0153712.g002">Fig 2</xref>. Hypothesis H1 predicted that negative tweets would receive more attention than positive tweets. Consistently with H1a, participants&#x02019; self-reports indicated significantly greater tweet attention and significantly greater gaze allocation on tablet when negative rather than positive tweets were displayed (<xref ref-type="table" rid="pone.0153712.t003">Table 3</xref> and <xref ref-type="fig" rid="pone.0153712.g002">Fig 2a</xref>), 95% CIs [0.08, 0.47] and [0.06, 0.60] units on the 7-step scale, respectively. Gaze tracking (H1b) and recognition memory task (H1c) provided congruent results: negative tweets elicited significantly longer gaze dwell times on tablet and received significantly better recognition memory than positive tweets (<xref ref-type="table" rid="pone.0153712.t003">Table 3</xref> and <xref ref-type="fig" rid="pone.0153712.g002">Fig 2b</xref>), 95% CIs [2%, 6%] and [2%, 8%], respectively. <xref ref-type="fig" rid="pone.0153712.g002">Fig 2c</xref> illustrates the average time course for tracked gaze allocation in more detail. Given that participants initiated a trial by touching the tablet, residual attention on the tablet can still be seen at the very beginning of trials (0 s). After onset (5 s), participants gazed exclusively at the television. Once the presentation of Twitter messages had begun (10 s onwards), participants began to divide their attention between the tablet and the television with an overall preference for the latter. As can be seen, gaze dwell times on tablet were at this phase consistently longer for negative than for positive tweets.</p><table-wrap id="pone.0153712.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.t003</object-id><label>Table 3</label><caption><title>LMM analysis results for tweet-related attentional measures.</title></caption><alternatives><graphic id="pone.0153712.t003g" xlink:href="pone.0153712.t003"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Variable</th><th align="left" rowspan="1" colspan="1">Effect</th><th align="center" rowspan="1" colspan="1">df<xref ref-type="table-fn" rid="t003fn002"><sup>a</sup></xref></th><th align="center" rowspan="1" colspan="1"><italic>F</italic></th><th align="center" rowspan="1" colspan="1"><italic>p</italic></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">SR Tweet Attention</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 21<xref ref-type="table-fn" rid="t003fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.01</td><td align="char" char="." rowspan="1" colspan="1">0.936</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 37<xref ref-type="table-fn" rid="t003fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">8.18</td><td align="char" char="." rowspan="1" colspan="1">0.007 <xref ref-type="table-fn" rid="t003fn006">**</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 514</td><td align="char" char="." rowspan="1" colspan="1">1.62</td><td align="char" char="." rowspan="1" colspan="1">0.204</td></tr><tr><td align="left" rowspan="1" colspan="1">SR Gaze on Tablet</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 21<xref ref-type="table-fn" rid="t003fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.06</td><td align="char" char="." rowspan="1" colspan="1">0.809</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 36<xref ref-type="table-fn" rid="t003fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">6.07</td><td align="char" char="." rowspan="1" colspan="1">0.019 <xref ref-type="table-fn" rid="t003fn005">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 516</td><td align="char" char="." rowspan="1" colspan="1">4.38</td><td align="char" char="." rowspan="1" colspan="1">0.037 <xref ref-type="table-fn" rid="t003fn005">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Tracked Gaze on Tablet</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 22<xref ref-type="table-fn" rid="t003fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.12</td><td align="char" char="." rowspan="1" colspan="1">0.728</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 231</td><td align="char" char="." rowspan="1" colspan="1">16.17</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t003fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 231</td><td align="char" char="." rowspan="1" colspan="1">6.15</td><td align="char" char="." rowspan="1" colspan="1">0.014 <xref ref-type="table-fn" rid="t003fn005">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Tweet Recognition</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 22<xref ref-type="table-fn" rid="t003fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.00</td><td align="char" char="." rowspan="1" colspan="1">0.988</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 552</td><td align="char" char="." rowspan="1" colspan="1">13.27</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t003fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">1, 552</td><td align="char" char="." rowspan="1" colspan="1">0.63</td><td align="char" char="." rowspan="1" colspan="1">0.429</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t003fn001"><p>SR = self-reported.</p></fn><fn id="t003fn002"><p><sup>a</sup>Welch-Sattertwaite approximation (rounded to the closest integer). Note that degrees of freedom for the error term depend on the included random variables.</p></fn><fn id="t003fn003"><p><sup>b</sup>The model included random intercepts for news stimuli.</p></fn><fn id="t003fn004"><p><sup>c</sup>The model included random slopes for this term across participants.</p></fn><fn id="t003fn005"><p>*<italic>p</italic> &#x0003c; 0.05.</p></fn><fn id="t003fn006"><p>**<italic>p</italic> &#x0003c; 0.01.</p></fn><fn id="t003fn007"><p>***<italic>p</italic> &#x0003c; 0.001</p></fn></table-wrap-foot></table-wrap><fig id="pone.0153712.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.g002</object-id><label>Fig 2</label><caption><title>Gaze allocation and attention results for positive and negative tweets.</title><p>(a) Tweet attention and tablet gaze allocation self-reports. (b) Behavioral attention measure results: tracked gaze allocation on tablet and tweet recognition memory. (c) Average time course for tracked gaze dwell time between television (news broadcasts) and tablet (Twitter messages). The time course has been smoothed with a 5-s moving average filter for illustration (analyses were based on average values). Error bars represent one SEM.</p></caption><graphic xlink:href="pone.0153712.g002"/></fig><p>RQ1b asked whether attentional responses to tweets would depend on the interaction between news and tweet valences. Interaction between news valence and tweet condition was significant for both self-reported and tracked viewing time measures (<xref ref-type="table" rid="pone.0153712.t003">Table 3</xref>). As can be seen in <xref ref-type="table" rid="pone.0153712.t001">Table 1</xref>, both of these variables showed a similar interaction effect. For positive news videos, negative tweets elicited significantly longer viewing times than positive tweets, 95% CIs [0.20, 0.85] and [4%, 10%] for self-reports and gaze dwell times, respectively. For negative news videos, the effects of negative and positive tweets did not differ, 95% CIs [&#x02013;0.19, 0.45] and [&#x02013;1%, 5%]. The interaction effect between news valence and tweet condition was not significant for self-reported attention on tweets or for tweet recognition memory (<xref ref-type="table" rid="pone.0153712.t003">Table 3</xref>).</p></sec><sec id="sec027"><title>Attention to News Videos</title><p>In hypothesis H2 we predicted that the presence of any tweets would decrease attention to news videos. <xref ref-type="table" rid="pone.0153712.t004">Table 4</xref> shows statistical analysis results for news-related attentional variables, and <xref ref-type="fig" rid="pone.0153712.g003">Fig 3</xref> illustrates attentional self-report and recognition memory results for news by tweet condition. The main effect of tweet condition was significant for self-reported news attention and both news recognition memory variables (<xref ref-type="table" rid="pone.0153712.t004">Table 4</xref>). As expected (H2a), news presented with tweets received significantly lower self-reported attention than news presented without tweets (<italic>p</italic> &#x0003c; 0.001), 95% CI for the difference [&#x02013;0.22, &#x02013;0.61] points on the 7-step scale. Similarly (H2b), news presented with tweets elicited significantly poorer factual (<italic>p</italic> &#x0003c; 0.001) and visual recognition memory (<italic>p</italic> &#x0003c; 0.001), 95% CIs [&#x02013;3%, &#x02013;12%] and [&#x02013;6%, &#x02013;12%].</p><table-wrap id="pone.0153712.t004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.t004</object-id><label>Table 4</label><caption><title>LMM analysis results for news-related attentional measures.</title></caption><alternatives><graphic id="pone.0153712.t004g" xlink:href="pone.0153712.t004"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Variable</th><th align="left" rowspan="1" colspan="1">Effect</th><th align="center" rowspan="1" colspan="1">df<xref ref-type="table-fn" rid="t004fn002"><sup>a</sup></xref></th><th align="center" rowspan="1" colspan="1"><italic>F</italic></th><th align="center" rowspan="1" colspan="1"><italic>p</italic></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">SR News Attention</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 22<xref ref-type="table-fn" rid="t004fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">1.36</td><td align="char" char="." rowspan="1" colspan="1">0.257</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 73<xref ref-type="table-fn" rid="t004fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">10.34</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t004fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 775</td><td align="char" char="." rowspan="1" colspan="1">1.57</td><td align="char" char="." rowspan="1" colspan="1">0.209</td></tr><tr><td align="left" rowspan="1" colspan="1">News Recognition (Fact.)</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 22<xref ref-type="table-fn" rid="t004fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.20</td><td align="char" char="." rowspan="1" colspan="1">0.659</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 73<xref ref-type="table-fn" rid="t004fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">6.02</td><td align="char" char="." rowspan="1" colspan="1">0.004 <xref ref-type="table-fn" rid="t004fn006">**</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 776</td><td align="char" char="." rowspan="1" colspan="1">4.55</td><td align="char" char="." rowspan="1" colspan="1">0.011 <xref ref-type="table-fn" rid="t004fn005">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">News Recognition (Vis.)</td><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 22<xref ref-type="table-fn" rid="t004fn003"><sup>b</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">4.58</td><td align="char" char="." rowspan="1" colspan="1">0.044 <xref ref-type="table-fn" rid="t004fn005">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 848</td><td align="char" char="." rowspan="1" colspan="1">17.01</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t004fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 848</td><td align="char" char="." rowspan="1" colspan="1">0.67</td><td align="char" char="." rowspan="1" colspan="1">0.514</td></tr><tr><td align="left" rowspan="1" colspan="1">Cardiac IBI</td><td align="left" rowspan="1" colspan="1">Baseline</td><td align="center" rowspan="1" colspan="1">1, 35</td><td align="char" char="." rowspan="1" colspan="1">321.32</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t004fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Epoch</td><td align="center" rowspan="1" colspan="1">1, 37<xref ref-type="table-fn" rid="t004fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">117.25</td><td align="char" char="." rowspan="1" colspan="1">&#x0003c; 0.001 <xref ref-type="table-fn" rid="t004fn007">***</xref></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence</td><td align="center" rowspan="1" colspan="1">1, 26<xref ref-type="table-fn" rid="t004fn003"><sup>b</sup></xref>,<xref ref-type="table-fn" rid="t004fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">1.48</td><td align="char" char="." rowspan="1" colspan="1">0.235</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 71<xref ref-type="table-fn" rid="t004fn004"><sup>c</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">2.95</td><td align="char" char="." rowspan="1" colspan="1">0.059</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">News Valence &#x000d7; Tweet Condition</td><td align="center" rowspan="1" colspan="1">2, 1457</td><td align="char" char="." rowspan="1" colspan="1">0.99</td><td align="char" char="." rowspan="1" colspan="1">0.372</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t004fn001"><p>SR = self-reported.</p></fn><fn id="t004fn002"><p><sup>a</sup>Welch-Sattertwaite approximation (rounded to the closest integer). Note that degrees of freedom for the error term depend on the included random variables.</p></fn><fn id="t004fn003"><p><sup>b</sup>The model included random intercepts for news stimuli.</p></fn><fn id="t004fn004"><p><sup>c</sup>The model included random slopes for this term across participants.</p></fn><fn id="t004fn005"><p>*<italic>p</italic> &#x0003c; 0.05.</p></fn><fn id="t004fn006"><p>**<italic>p</italic> &#x0003c; 0.01.</p></fn><fn id="t004fn007"><p>***<italic>p</italic> &#x0003c; 0.001</p></fn></table-wrap-foot></table-wrap><fig id="pone.0153712.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.g003</object-id><label>Fig 3</label><caption><title>News attention self-report and recognition memory results by tweet condition.</title><p>Significant differences between conditions are marked with an asterisk (&#x02018;*&#x02019;). Error bars represent one SEM.</p></caption><graphic xlink:href="pone.0153712.g003"/></fig><p>Hypothesis H2c predicted that news presented with tweets would elicit shorter IBIs (i.e., weaker cardiac orienting responses) than news presented without tweets. <xref ref-type="fig" rid="pone.0153712.g004">Fig 4</xref> illustrates average time courses within a trial for all physiological variables by tweet condition. As can be seen in <xref ref-type="fig" rid="pone.0153712.g004">Fig 4a</xref>, cardiac IBIs showed an overall increasing trend (cardiac deceleration) in all conditions. A slight decrease (cardiac acceleration) can be seen 10&#x02013;15 s after the trial onsets, which apparently reflects a late cardiac response to heightened sympathetic arousal at the beginning of trials (cf. iSCR responses in <xref ref-type="fig" rid="pone.0153712.g004">Fig 4b</xref>). Consistently with H2c, both positive and negative tweets appeared to elicit shorter IBIs beginning approximately 25 s after the trial onsets. Although the main effect of tweet condition on IBI responses was only marginally significant (<italic>p</italic> = 0.059; <xref ref-type="table" rid="pone.0153712.t004">Table 4</xref>), planned contrast for positive and negative versus no tweets reached statistical significance (<italic>p</italic> = 0.028). Consistently with our prediction (H2c), news presented with tweets elicited significantly shorter average IBIs than news presented without tweets, 95% CI [&#x02013;1, &#x02013;10] ms.</p><fig id="pone.0153712.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0153712.g004</object-id><label>Fig 4</label><caption><title>Psychophysiological activations by tweet condition.</title><p>Average time courses for (a) cardiac responses (IBI), (b) skin conductance responses (iSCR), (c) facial electromyography responses at zygomaticus major location (EMG-ZM/OO), and (d) facial electromyography responses at corrugator supercilii (CS) location. Facial EMG activations at orbicularis oculi (OO) location were almost identical to those of EMG-ZM and are not presented separately. Time courses are presented for 5-s epochs. Black bars at the upper corners represent &#x000b1; 1 SEM.</p></caption><graphic xlink:href="pone.0153712.g004"/></fig><p>We also predicted that negative tweets would draw more attention away from the news videos than positive tweets (H3). Although the main effect of tweet condition was significant for self-reported news attention and both recognition memory scores (<xref ref-type="table" rid="pone.0153712.t004">Table 4</xref>), planned comparisons did not indicate significant differences between negative and positive tweets. News videos presented with negative tweets received marginally but not significantly (<italic>p</italic> = 0.073) lower news attention ratings than news videos presented with positive tweets (H3a), 95% CI [&#x02013;0.44, 0.02]. Contrary to H3b, news videos presented with negative tweets did not receive significantly poorer factual (<italic>p</italic> = 0.693) or visual recognition scores (<italic>p</italic> = 0.186) than news videos presented with positive tweets, 95% CIs [&#x02013;4%, 6%] and [&#x02013;1%, 6%], respectively. Furthermore, cardiac IBIs did not differ significantly for news presented with negative and positive tweets (H3c; <italic>p</italic> = 0.356), 95% CI [&#x02013;8, 3] ms.</p><p><xref ref-type="table" rid="pone.0153712.t004">Table 4</xref> also shows two unpredicted statistically significant effects. First, the main effect of news valence on visual recognition scores was significant such that positive news were recognized better than negative news, 95% CI [0%, 20%]. Second, the interaction between news valence and tweet condition was significant for factual recognition scores. A follow-up test for the interaction between news and tweet valences was not significant (<italic>p</italic> = 0.084), however. Specifically, the effects of negative and positive tweets did not differ significantly when paired with negative and positive news videos, 95% CIs [&#x02013;9%, 4%] and [&#x02013;2%, 12%], respectively. Strictly speaking, statistical significance levels in these unplanned tests should have been corrected for multiple comparisons. Given that these effects would not have survived such correction (corrected &#x003b1; = 0.05/12 = 0.004 [for 12 dependent variables]) and neither one of them was significant for both recognition scores, we considered these effects as chance findings.</p></sec></sec><sec sec-type="conclusions" id="sec028"><title>Discussion</title><p>The present investigation studied the attentional effects of negative and positive Twitter messages on simultaneously presented news broadcasts. The main finding was that negative tweets draw more gaze dwell time and are recognized better than positive tweets. Increased gaze dwell time on negative tweets was supported both by gaze tracking data and subjective evaluations. These results cannot be explained by varying Twitter message lengths or intensities, given that the positive and negative tweets were matched in length and the strength of their expressed attitudes. Furthermore, tweet conditions were counterbalanced within the individual news, which means that news-specific idiosyncratic results should have been averaged out.</p><p>The above results are consistent with well-known informational negativity effects, which have demonstrated that negative stimuli prompt more attention and more detailed cognitive processing than equally intense positive stimuli [<xref rid="pone.0153712.ref012" ref-type="bibr">12</xref>,<xref rid="pone.0153712.ref013" ref-type="bibr">13</xref>]. Participants&#x02019; self-reports and tracked gaze dwell times can be considered as direct subjective and objective attentional indices, respectively. Furthermore, recognition memory has been considered as a good index of mediated message encoding [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>]. Hence, the present better recognition memory results would suggest that more resources were allocated to the encoding of negative tweets than to the encoding of positive tweets. Better recognition memory results for negative tweets are consistent with previous studies which have, for example, demonstrated enhanced recognition memory for negative than for positive public service announcements [<xref rid="pone.0153712.ref020" ref-type="bibr">20</xref>] and political advertisements [<xref rid="pone.0153712.ref021" ref-type="bibr">21</xref>].</p><p>Our results confirmed that the presence of tweets&#x02014;that is, media multitasking&#x02014;decreases attention to news as measured with both self-reports and recognition memory. This finding is consistent with the LC4MP model [<xref rid="pone.0153712.ref006" ref-type="bibr">6</xref>], which suggests that limited resources need to be allocated simultaneously to encoding, storage, and retrieval processes. Given that textual tweets were presented simultaneously with a continuous audiovisual news stream, encoding resources assigned to tweets should have reduced similar resources for news. Other previous studies have demonstrated that a simultaneous reading task elicits decreased recognition memory for television entertainment broadcasts [<xref rid="pone.0153712.ref024" ref-type="bibr">24</xref>] and that textual news tickers elicit decreased recognition memory for news broadcasts [<xref rid="pone.0153712.ref026" ref-type="bibr">26</xref>]. Our recognition memory results are consistent with these findings. Furthermore, the present results demonstrate that semantic similarity between the secondary and primary media tasks does not compensate for the increased attentional cost of media multitasking. The extent of semantic similarity between the present social media messages and news broadcasts could be debated, however, because the former addressed viewers&#x02019; opinions about the news rather than provided additional information about the news themselves. It is possible that the disadvantages of media multitasking could vary depending on whether the two media channels are fully complementary (e.g., news broadcasts and textual messages repeating their focal contents), related (e.g., the present task) or unrelated (e.g., news broadcasts and unrelated twitter messages). This question could be investigated in future studies by explicitly comparing such conditions with each other.</p><p>A limitation of the present findings is that participants were explicitly required to attend both news and tweets, which differs from a natural viewing condition in which viewers can choose for themselves on what to focus and when. Consequently, it is possible that the detrimental effects of multitasking could be weaker in everyday media use. Another limitation of the present study is that our measurements tapped only into the encoding phase of the LC4MP model [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>], whereas tweets could have been expected to influence also the storage and retrieval of information. Storage and retrieval performance could be tested in future studies, for example, by utilizing cued and free recall memory tasks. Secondary task reaction time measurements could also be used as an additional index of encoding [<xref rid="pone.0153712.ref005" ref-type="bibr">5</xref>].</p><p>We expected that because cardiac decelerations indicative of orienting responses should be driven mainly by events in the television broadcasts, the presence of tweets should decrease cardiac decelerations (i.e., elicit relatively shorter IBIs). Our results gave tentative evidence for this prediction even though the results failed to reach statistical significance and the effect size was small (i.e., at most 10 ms shorter IBIs for news presented with tweets). However, we note that the straightforward IBI measure is limited as an attentional index because it is reciprocally sensitive to both arousal and attention [<xref rid="pone.0153712.ref032" ref-type="bibr">32</xref>]. Heart rate variability measures such as the respiratory sinus arrhythmia (RSA) would have been more unequivocal attentional measures, however, this option was not available for the present analyses given that frequency domain calculations for RSA would have required longer stimuli (60 s at the bare minimum [<xref rid="pone.0153712.ref053" ref-type="bibr">53</xref>]). Furthermore, it is unlikely that heightened arousal would have confounded our IBI results given that the presence of tweets did not elicit elevated arousal as measured with EDA activity or SAM arousal self-reports. That is, given that EDA is unilaterally sensitive to sympathetic arousal [<xref rid="pone.0153712.ref032" ref-type="bibr">32</xref>], it is plausible that the observed small IBI changes were due to attentional rather than arousal effects.</p><p>We also predicted that the increased attention to negative tweets would occur at the cost of decreased attention to news broadcast. Our results did not support this prediction, however. Self-reported news attention was marginally lower for news presented with than without tweets; however, this findings was not corroborated by recognition memory results. Taken together, the present results suggest that although negative social media messages draw more attention towards themselves, participants are able to compensate for the imposed attentional demands. A limitation of the present study is that we used a fixed and relatively low frequency of twitter messages. Increasing the number of tweets per each news broadcast could increase the attentional demands of tweets and also compromise the cognitive processing of news. Hence, future studies could test whether increasing the number of tweets from that of the present study would elicit more pronounced attentional effects for tweets in general and negative tweets in particular.</p><p>Although tweets expressing other individuals&#x02019; negative and positive attitudes towards the news broadcasts modulated participants&#x02019; retrospective pleasantness evaluations, facial EMG measurements failed to indicate consistent emotional reactions at the time when the news and tweets were being viewed. This was somewhat unexpected, given that facial EMG measurements are recognized as a valid index of emotional valence [<xref rid="pone.0153712.ref036" ref-type="bibr">36</xref>] and they were in the present investigation clearly sensitive to the valence of news and the valence of background mood (as described in <xref ref-type="supplementary-material" rid="pone.0153712.s001">S1 Appendix</xref>). The present findings suggest that negative and positive social media messages modulate retrospective judgments but that they do not function as emotional signals <italic>per se</italic>. This suggestion is consistent with the affect heuristic framework [<xref rid="pone.0153712.ref054" ref-type="bibr">54</xref>], which suggests that objects are tagged to varying degrees with positive or negative affective tags that are used as heuristic cues when making evaluative judgments. In the present study, positive and negative tags may have become associated with news broadcasts while they were being viewed and consequently functioned as affective tags in retrospective judgments.</p><p>The principle of negativity dominance [<xref rid="pone.0153712.ref013" ref-type="bibr">13</xref>] led to the research question of whether the emotional and attentional effects of negative tweets would be stronger when paired with positive than with negative news. We found that negative as compared with positive tweets elicited greater self-reported unpleasantness but only when they were paired with positive news. Similar effect was observed for self-reported and tracked gaze allocation measures. Furthermore, our results showed that television was clearly the primary media in the present context. Hence, consistently with the principle of negativity dominance, the present results indicate that even weak negative signals (tweets) can modulate emotional and attentional responses to strong positive stimuli (news), whereas weak positive signals do not exert similar effects on strong negative signals. Similarly as above, however, negative tweets did not compromise the attentional processing of news information even when they were paired with positive news broadcasts.</p><p>Taken together, our results demonstrate for the first time that negative information presented on a second screen draws more attention to itself than similar positive information. This finding is a novel replication of the negativity bias phenomenon in the context of media multitasking. However, although negative information drew more attention to itself, this effect was not sufficiently strong to compromise the attentional processing of the primary media. On the other hand, our results do demonstrate that second-screen information has significant debilitating effects on attention. These results have practical implications for the television industry. Many television shows have deliberately incorporated Twitter feedback in their broadcasts. Although this parallel tweet narrative may enrich the viewing experience, it also inevitably draws attention away from the primary broadcast. Television broadcast producers might hence want to avoid presenting second-screen information in cognitively demanding parts of their programs. Although the present study demonstrates that negative emotional information presented on a second screen draws more attention than equally strong positive information, the present findings also suggest that this effect does not inflate the detrimental effects of any information presented on second screens.</p></sec><sec sec-type="supplementary-material" id="sec029"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0153712.s001"><label>S1 Appendix</label><caption><title>Excluded data.</title><p>(PDF)</p></caption><media xlink:href="pone.0153712.s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0153712.s002"><label>S2 Appendix</label><caption><title>Linear Mixed Model equations.</title><p>(PDF)</p></caption><media xlink:href="pone.0153712.s002.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0153712.s003"><label>S3 Appendix</label><caption><title>In accordance with the guidelines of PLOS ONE concerning data availability, Appendix S3 contains all SPSS data analysis files for the experiment.</title><p>To protect participants&#x02019; privacy, participant identifiers have been anonymized and no participant-related data are included in the data files.</p><p>(ZIP)</p></caption><media xlink:href="pone.0153712.s003.zip"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We thank Dr. Stina Westman for help in designing the experiment; Dr. Kari Kallinen for help in data collection; and Mari Laine-Hernandez, MSc (Tech), for help in data analysis. We also thank the Finnish Broadcasting Company for access into television broadcasts.</p></ack><ref-list><title>References</title><ref id="pone.0153712.ref001"><label>1</label><mixed-citation publication-type="book"><name><surname>Rideout</surname><given-names>V</given-names></name>, <name><surname>Foehr</surname><given-names>U</given-names></name>, <name><surname>Roberts</surname><given-names>D</given-names></name>. <chapter-title>Generation M&#x0202f;: Media in the lives of 8-to 18-year-olds</chapter-title>
<publisher-name>Henry J. Kaiser Family Foundation</publisher-name>
<publisher-loc>Menlo Park, CA</publisher-loc>; <year>2010</year> Available: <ext-link ext-link-type="uri" xlink:href="http://www.eric.ed.gov/ERICWebPortal/recordDetail?accno=ED527859">http://www.eric.ed.gov/ERICWebPortal/recordDetail?accno=ED527859</ext-link></mixed-citation></ref><ref id="pone.0153712.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Voorveld</surname><given-names>HAM</given-names></name>, <name><surname>van der Goot</surname><given-names>M</given-names></name>. <article-title>Age differences in media multitasking: A diary study</article-title>. <source>J Broadcast Electron Media</source>. <year>2013</year>;<volume>57</volume>(<issue>3</issue>): <fpage>392</fpage>&#x02013;<lpage>408</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/08838151.2013.816709">10.1080/08838151.2013.816709</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref003"><label>3</label><mixed-citation publication-type="other">Twitter. Available: <ext-link ext-link-type="uri" xlink:href="http://twitter.com">http://twitter.com</ext-link></mixed-citation></ref><ref id="pone.0153712.ref004"><label>4</label><mixed-citation publication-type="other">Lochrie M, Coulton P. Sharing the viewing experience through second screens. In: 10th European Conference on Interactive TV and Video (EuroiTV). 2012. p. 199&#x02013;202. Available: <ext-link ext-link-type="uri" xlink:href="http://eprints.lancs.ac.uk/55832/">http://eprints.lancs.ac.uk/55832/</ext-link></mixed-citation></ref><ref id="pone.0153712.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Lang</surname><given-names>A</given-names></name>. <article-title>The limited capacity model of mediated message processing</article-title>. <source>J Commun</source>. <year>2000</year>;<volume>50</volume>(<issue>1</issue>): <fpage>46</fpage>&#x02013;<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-2466.2000.tb02833.x">10.1111/j.1460-2466.2000.tb02833.x</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref006"><label>6</label><mixed-citation publication-type="book"><name><surname>Lang</surname><given-names>A</given-names></name>. <chapter-title>The limited capacity model of motivated mediated message processing</chapter-title> In: <name><surname>Nabi</surname><given-names>R</given-names></name>, <name><surname>Oliver</surname><given-names>MB</given-names></name>, editors. <source>The SAGE handbook of mass media processes and effects</source>. <publisher-loc>California</publisher-loc>: <publisher-name>SAGE Publications</publisher-name>; <year>2009</year> p. <fpage>193</fpage>&#x02013;<lpage>204</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Baumeister</surname><given-names>RF</given-names></name>, <name><surname>Bratslavsky</surname><given-names>E</given-names></name>, <name><surname>Finkenauer</surname><given-names>C</given-names></name>, <name><surname>Vohs</surname><given-names>KD</given-names></name>. <article-title>Bad is stronger than good</article-title>. <source>Rev Gen Psychol</source>. <year>2001</year>;<volume>5</volume>(<issue>4</issue>): <fpage>323</fpage>&#x02013;<lpage>70</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Cacioppo</surname><given-names>JT</given-names></name>, <name><surname>Gardner</surname><given-names>WL</given-names></name>, <name><surname>Berntson</surname><given-names>GG</given-names></name>. <article-title>Beyond bipolar conceptualizations and measures: The case of attitudes and evaluative space</article-title>. <source>Personal Soc Psychol Rev</source>. <year>1997</year>;<volume>1</volume>(<issue>1</issue>): <fpage>3</fpage>&#x02013;<lpage>25</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1207/s15327957pspr0101_2">10.1207/s15327957pspr0101_2</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Fiske</surname><given-names>ST</given-names></name>. <article-title>Attention and weight in person perception: The impact of negative and extreme behavior</article-title>. <source>J Pers Soc Psychol</source>. <year>1980</year>;<volume>38</volume>(<issue>6</issue>): <fpage>889</fpage>&#x02013;<lpage>906</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Frijda</surname><given-names>NH</given-names></name>. <article-title>The laws of emotion</article-title>. <source>Am Psychol</source>. <year>1988</year>;<volume>43</volume>(<issue>5</issue>): <fpage>349</fpage>&#x02013;<lpage>58</lpage>.<pub-id pub-id-type="pmid">3389582</pub-id></mixed-citation></ref><ref id="pone.0153712.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Kahneman</surname><given-names>D</given-names></name>, <name><surname>Tversky</surname><given-names>A</given-names></name>. <article-title>Choices, values, and frames</article-title>. <source>Am Psychol</source>. <year>1984</year>;<volume>39</volume>(<issue>4</issue>): <fpage>341</fpage>&#x02013;<lpage>50</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Peeters</surname><given-names>G</given-names></name>, <name><surname>Czapinski</surname><given-names>J</given-names></name>. <article-title>Positive-negative asymmetry in evaluations: The distinction between affective and informational negativity effects</article-title>. <source>Eur Rev Soc Psychol</source>. <year>1990</year>;<volume>1</volume>(<issue>1</issue>): <fpage>33</fpage>&#x02013;<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/14792779108401856">10.1080/14792779108401856</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Rozin</surname><given-names>P</given-names></name>, <name><surname>Royzman</surname><given-names>EB</given-names></name>. <article-title>Negativity bias, negativity dominance, and contagion</article-title>. <source>Personal Soc Psychol Rev</source>. <year>2001</year>;<volume>5</volume>(<issue>4</issue>): <fpage>296</fpage>&#x02013;<lpage>320</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1207/S15327957PSPR0504_2">10.1207/S15327957PSPR0504_2</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Taylor</surname><given-names>SE</given-names></name>. <article-title>Asymmetrical effects of positive and negative events: The mobilization-minimization hypothesis</article-title>. <source>Psychol Bull</source>. <year>1991</year>;<volume>110</volume>(<issue>1</issue>): <fpage>67</fpage>&#x02013;<lpage>85</lpage>. <pub-id pub-id-type="pmid">1891519</pub-id></mixed-citation></ref><ref id="pone.0153712.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Cacioppo</surname><given-names>JT</given-names></name>, <name><surname>Gardner</surname><given-names>WL</given-names></name>, <name><surname>Berntson</surname><given-names>GG</given-names></name>. <article-title>The affect system has parallel and integrative processing components: Form follows function</article-title>. <source>J Pers Soc Psychol</source>. <year>1999</year>;<volume>76</volume>(<issue>5</issue>): <fpage>839</fpage>&#x02013;<lpage>55</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Pratto</surname><given-names>F</given-names></name>, <name><surname>John</surname><given-names>OP</given-names></name>. <article-title>Automatic vigilance: The attention-grabbing power of negative social information</article-title>. <source>J Pers Soc Psychol</source>. <year>1991</year>;<volume>61</volume>(<issue>3</issue>): <fpage>380</fpage>&#x02013;<lpage>91</lpage>. <pub-id pub-id-type="pmid">1941510</pub-id></mixed-citation></ref><ref id="pone.0153712.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Yechiam</surname><given-names>E</given-names></name>, <name><surname>Hochman</surname><given-names>G</given-names></name>. <article-title>Losses as modulators of attention: Review and analysis of the unique effects of losses over gains</article-title>. <source>Psychol Bull</source>. <year>2013</year>;<volume>139</volume>: <fpage>497</fpage>&#x02013;<lpage>518</lpage>. <pub-id pub-id-type="pmid">22823738</pub-id></mixed-citation></ref><ref id="pone.0153712.ref018"><label>18</label><mixed-citation publication-type="book"><name><surname>Lang</surname><given-names>A</given-names></name>. <chapter-title>Motivated cognition (LC4MP): The influence of appetitive and aversive activation on the processing of video games</chapter-title> In: <name><surname>Messarsis</surname><given-names>P</given-names></name>, <name><surname>Humphries</surname><given-names>L</given-names></name>, editors. <source>Digital media: Transformation in human communication</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Peter Lang</publisher-name>; <year>2006</year> p. <fpage>237</fpage>&#x02013;<lpage>56</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Yegiyan</surname><given-names>NS</given-names></name>, <name><surname>Lang</surname><given-names>A</given-names></name>. <article-title>Processing central and peripheral detail: How content arousal and emotional tone influence encoding</article-title>. <source>Media Psychol</source>. <year>2010</year>;<volume>13</volume>(<issue>1</issue>): <fpage>77</fpage>&#x02013;<lpage>99</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/15213260903563014">10.1080/15213260903563014</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Reeves</surname><given-names>BJ</given-names></name>, <name><surname>Newhagen</surname><given-names>JE</given-names></name>, <name><surname>Maibach</surname><given-names>E</given-names></name>, <name><surname>Basil</surname><given-names>M</given-names></name>, <name><surname>Kurz</surname><given-names>K</given-names></name>. <article-title>Negative and positive television messages: Effects of message type and context on attention and memory</article-title>. <source>Am Behav Sci</source>. <year>1994</year>;<volume>34</volume>(<issue>6</issue>): <fpage>679</fpage>&#x02013;<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0002764291034006006">10.1177/0002764291034006006</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Bradley</surname><given-names>SD</given-names></name>, <name><surname>Angelini</surname><given-names>JR</given-names></name>, <name><surname>Lee</surname><given-names>S</given-names></name>. <article-title>Psychophysiological and memory effects of negative political ads: Aversive, arousing, and well remembered</article-title>. <source>J Advert</source>. <year>2007</year>;<volume>36</volume>(<issue>4</issue>): <fpage>115</fpage>&#x02013;<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2753/JOA0091-3367360409">10.2753/JOA0091-3367360409</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref022"><label>22</label><mixed-citation publication-type="book"><name><surname>Pashler</surname><given-names>H</given-names></name>. <chapter-title>Task switching and multitask performance</chapter-title> In: <name><surname>Montell</surname><given-names>S</given-names></name>, <name><surname>Driver</surname><given-names>J</given-names></name>, editors. <source>Control of cognitive processes: Attention and performance: XVIII</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>2000</year> p. <fpage>277</fpage>&#x02013;<lpage>308</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Salvucci</surname><given-names>DD</given-names></name>, <name><surname>Taatgen</surname><given-names>NA</given-names></name>. <article-title>Threaded cognition: An integrated theory of concurrent multitasking</article-title>. <source>Psychol Rev</source>. <year>2008</year>;<volume>115</volume>(<issue>1</issue>): <fpage>101</fpage>&#x02013;<lpage>30</lpage>. <pub-id pub-id-type="pmid">18211187</pub-id></mixed-citation></ref><ref id="pone.0153712.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>W</given-names></name>, <name><surname>Jeong</surname><given-names>S-H</given-names></name>, <name><surname>Fishbein</surname><given-names>M</given-names></name>. <article-title>Situational factors competing for attention: The interaction effect of multitasking and sexually explicit content on TV recognition</article-title>. <source>J Media Psychol</source>. <year>2010</year>;<volume>22</volume>(<issue>1</issue>): <fpage>2</fpage>&#x02013;<lpage>13</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1027/1864-1105/a000002">10.1027/1864-1105/a000002</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Srivastava</surname><given-names>J</given-names></name>. <article-title>Media multitasking performance: Role of message relevance and formatting cues in online environments</article-title>. <source>Comput Human Behav</source>. <year>2013</year>;<volume>29</volume>(<issue>3</issue>): <fpage>888</fpage>&#x02013;<lpage>95</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.chb.2012.12.023">10.1016/j.chb.2012.12.023</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Bergen</surname><given-names>L</given-names></name>, <name><surname>Grimes</surname><given-names>T</given-names></name>, <name><surname>Potter</surname><given-names>D</given-names></name>. <article-title>How attention partitions itself during simultaneous message presentations</article-title>. <source>Hum Commun Res</source>. <year>2005</year>;<volume>31</volume>(<issue>3</issue>): <fpage>311</fpage>&#x02013;<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1468-2958.2005.tb00874.x">10.1111/j.1468-2958.2005.tb00874.x</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Armstrong</surname><given-names>GB</given-names></name>, <name><surname>Chung</surname><given-names>L</given-names></name>. <article-title>Background television and reading memory in context: Assessing TV interference and facilitative context effects on encoding versus retrieval processes</article-title>. <source>Communic Res</source>. <year>2000</year>;<volume>27</volume>(<issue>3</issue>): <fpage>327</fpage>&#x02013;<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/009365000027003003">10.1177/009365000027003003</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Furnham</surname><given-names>A</given-names></name>, <name><surname>Gunter</surname><given-names>B</given-names></name>, <name><surname>Peterson</surname><given-names>E</given-names></name>. <article-title>Television distraction and the performance of introverts and extroverts</article-title>. <source>Appl Cogn Psychol</source>. <year>1994</year>;<volume>8</volume>(<issue>7</issue>): <fpage>705</fpage>&#x02013;<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/acp.2350080708">10.1002/acp.2350080708</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Pool</surname><given-names>MM</given-names></name>, <name><surname>Koolstra</surname><given-names>CM</given-names></name>, <name><surname>van der Voort</surname><given-names>THA</given-names></name>. <article-title>Distraction effects of background soap operas on homework performance: An experimental study enriched with observational data</article-title>. <source>Educ Psychol</source>. <year>2003</year>;<volume>23</volume>(<issue>4</issue>): <fpage>361</fpage>&#x02013;<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/01443410303211">10.1080/01443410303211</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Grimes</surname><given-names>T</given-names></name>. <article-title>Mild auditory-visual dissonance in television news may exceed viewer attentional capacity</article-title>. <source>Hum Commun Res</source>. <year>1991</year>;<volume>18</volume>(<issue>2</issue>): <fpage>268</fpage>&#x02013;<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1468-2958.1991.tb00546.x">10.1111/j.1468-2958.1991.tb00546.x</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Z</given-names></name>, <name><surname>Irwin</surname><given-names>M</given-names></name>, <name><surname>Cooper</surname><given-names>C</given-names></name>, <name><surname>Srivastava</surname><given-names>J</given-names></name>. <article-title>Multidimensions of media multitasking and adaptive media selection</article-title>. <source>Hum Commun Res</source>. <year>2015</year>;<volume>41</volume>: <fpage>102</fpage>&#x02013;<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/hcre.12042">10.1111/hcre.12042</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Ravaja</surname><given-names>N</given-names></name>. <article-title>Contributions of psychophysiology to media research: Review and recommendations</article-title>. <source>Media Psychol</source>. <year>2004</year>;<volume>6</volume>(<issue>2</issue>): <fpage>193</fpage>&#x02013;<lpage>235</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1207/s1532785xmep0602_4">10.1207/s1532785xmep0602_4</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Detenber</surname><given-names>BH</given-names></name>, <name><surname>Simons</surname><given-names>RF</given-names></name>, <name><surname>Bennett</surname><given-names>GG</given-names></name>. <article-title>Roll &#x02018;em!: The effects of picture motion on emotional responses</article-title>. <source>J Broadcast Electron Media &#x00026; Electron Media</source>. <year>1998</year>;<volume>42</volume>(<issue>1</issue>): <fpage>113</fpage>&#x02013;<lpage>27</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/08838159809364437">10.1080/08838159809364437</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Simons</surname><given-names>RF</given-names></name>, <name><surname>Detenber</surname><given-names>BH</given-names></name>, <name><surname>Reiss</surname><given-names>JE</given-names></name>, <name><surname>Shults</surname><given-names>CW</given-names></name>. <article-title>Image motion and context: A between- and within-subjects comparison</article-title>. <source>Psychophysiology</source>. <year>2000</year>;<volume>37</volume>(<issue>5</issue>): <fpage>706</fpage>&#x02013;<lpage>610</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/1469-8986.3750706">10.1111/1469-8986.3750706</ext-link></comment>
<pub-id pub-id-type="pmid">11037047</pub-id></mixed-citation></ref><ref id="pone.0153712.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Bolls</surname><given-names>PD</given-names></name>, <name><surname>Lang</surname><given-names>A</given-names></name>, <name><surname>Potter</surname><given-names>RF</given-names></name>. <article-title>The effects of message valence and listener arousal on attention, memory, and facial muscular responses to radio advertisements</article-title>. <source>Communic Res</source>. <year>2001</year>;<volume>28</volume>(<issue>5</issue>): <fpage>627</fpage>&#x02013;<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/009365001028005003">10.1177/009365001028005003</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Lang</surname><given-names>PJ</given-names></name>, <name><surname>Greenwald</surname><given-names>MK</given-names></name>, <name><surname>Bradley</surname><given-names>MM</given-names></name>, <name><surname>Hamm</surname><given-names>AO</given-names></name>. <article-title>Looking at pictures: Affective, facial, visceral, and behavioral reactions</article-title>. <source>Psychophysiology</source>. <year>1993</year>;<volume>30</volume>(<issue>3</issue>): <fpage>261</fpage>&#x02013;<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1469-8986.1993.tb03352.x">10.1111/j.1469-8986.1993.tb03352.x</ext-link></comment>
<pub-id pub-id-type="pmid">8497555</pub-id></mixed-citation></ref><ref id="pone.0153712.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Yechiam</surname><given-names>E</given-names></name>, <name><surname>Hochman</surname><given-names>G</given-names></name>. <article-title>Loss attention in a dual-task setting</article-title>. <source>Psychol Sci</source>. <year>2014</year>;<volume>25</volume>: <fpage>494</fpage>&#x02013;<lpage>502</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797613510725">10.1177/0956797613510725</ext-link></comment>
<pub-id pub-id-type="pmid">24357614</pub-id></mixed-citation></ref><ref id="pone.0153712.ref038"><label>38</label><mixed-citation publication-type="other">Finnish Advisory Board on Research Integrity. Responsible conduct of research and procedures for handling allegations of misconduct in Finland&#x02014;RCR guidelines. 2012. Available: <ext-link ext-link-type="uri" xlink:href="http://www.tenk.fi/en/">http://www.tenk.fi/en/</ext-link></mixed-citation></ref><ref id="pone.0153712.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Grant</surname><given-names>DA</given-names></name>. <article-title>The Latin square principle in the design and analysis of psychological experiments</article-title>. <source>Psychol Bull</source>. <year>1948</year>;<volume>45</volume>(<issue>5</issue>): <fpage>427</fpage>&#x02013;<lpage>42</lpage>. <pub-id pub-id-type="pmid">18885731</pub-id></mixed-citation></ref><ref id="pone.0153712.ref040"><label>40</label><mixed-citation publication-type="other">Yle News. Available: <ext-link ext-link-type="uri" xlink:href="http://www.yle.fi">http://www.yle.fi</ext-link></mixed-citation></ref><ref id="pone.0153712.ref041"><label>41</label><mixed-citation publication-type="other">ITU-R. General viewing conditions for subjective assessment of quality of SDTV and HDTV television pictures on flat panel displays (Recommendation ITU-R BT.2022). Geneva; 2012. Available: <ext-link ext-link-type="uri" xlink:href="http://www.itu.int/rec/R-REC-BT.2022-0-201208-I/en">http://www.itu.int/rec/R-REC-BT.2022-0-201208-I/en</ext-link></mixed-citation></ref><ref id="pone.0153712.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Bradley</surname><given-names>MM</given-names></name>, <name><surname>Lang</surname><given-names>PJ</given-names></name>. <article-title>Measuring emotion: The self-assessment manikin and the semantic differential</article-title>. <source>J Behav Ther Exp Psychiatry</source>. <year>1994</year>;<volume>25</volume>(<issue>1</issue>): <fpage>49</fpage>&#x02013;<lpage>59</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0005-7916(94)90063-9">10.1016/0005-7916(94)90063-9</ext-link></comment>
<pub-id pub-id-type="pmid">7962581</pub-id></mixed-citation></ref><ref id="pone.0153712.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Ravaja</surname><given-names>N</given-names></name>. <article-title>Effects of image motion on a small screen on emotion, attention, and memory: Moving-face versus static-face newscaster</article-title>. <source>J Broadcast Electron Media</source>. <year>2004</year>;<volume>48</volume>(<issue>1</issue>): <fpage>108</fpage>&#x02013;<lpage>33</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1207/s15506878jobem4801_6">10.1207/s15506878jobem4801_6</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Schneider</surname><given-names>S</given-names></name>, <name><surname>Laurion</surname><given-names>S</given-names></name>. <article-title>Do we know what we&#x02019;ve learned from listening to the news?</article-title>
<source>Mem Cognit</source>. <year>1993</year>;<volume>21</volume>(<issue>2</issue>): <fpage>198</fpage>&#x02013;<lpage>209</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/bf03202733">10.3758/bf03202733</ext-link></comment>
<pub-id pub-id-type="pmid">8469129</pub-id></mixed-citation></ref><ref id="pone.0153712.ref045"><label>45</label><mixed-citation publication-type="book"><name><surname>Wagner</surname><given-names>J</given-names></name>, <name><surname>Kim</surname><given-names>J</given-names></name>, <name><surname>Andr</surname><given-names>E</given-names></name>. <chapter-title>From physiological signals to emotions: implementing and comparing selected methods for feature extraction and classification</chapter-title> In: <source>IEEE International Conference on Multimedia &#x00026; Expo</source>. <publisher-loc>Amsterdam</publisher-loc>; <year>2005</year> p. <fpage>940</fpage>&#x02013;<lpage>3</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Fridlund</surname><given-names>AJ</given-names></name>, <name><surname>Cacioppo</surname><given-names>JT</given-names></name>. <article-title>Guidelines for human electromyographic research</article-title>. <source>Psychophysiology. Wiley Online Library</source>; <year>1986</year>;<volume>23</volume>(<issue>5</issue>): <fpage>567</fpage>&#x02013;<lpage>89</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1469-8986.1986.tb00676.x">10.1111/j.1469-8986.1986.tb00676.x</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Benedek</surname><given-names>M</given-names></name>, <name><surname>Kaernbach</surname><given-names>C</given-names></name>. <article-title>A continuous measure of phasic electrodermal activity</article-title>. <source>J Neurosci Methods. Elsevier B.V</source>.; <year>2010</year>;<volume>190</volume>(<issue>1</issue>): <fpage>80</fpage>&#x02013;<lpage>91</lpage>.</mixed-citation></ref><ref id="pone.0153712.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Hayes</surname><given-names>AF</given-names></name>. <article-title>A primer on multilevel modeling</article-title>. <source>Hum Commun Res.</source>;<volume>32</volume>(<issue>4</issue>): <fpage>385</fpage>&#x02013;<lpage>410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1468-2958.2006.00281.x">10.1111/j.1468-2958.2006.00281.x</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Hoffman</surname><given-names>L</given-names></name>, <name><surname>Rovine</surname><given-names>MJ</given-names></name>. <article-title>Multilevel models for the experimental psychologist: Foundations and illustrative examples</article-title>. <source>Behav Res Methods</source>. <year>2007</year>;<volume>39</volume>(<issue>1</issue>): <fpage>101</fpage>&#x02013;<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/bf03192848">10.3758/bf03192848</ext-link></comment>
<pub-id pub-id-type="pmid">17552476</pub-id></mixed-citation></ref><ref id="pone.0153712.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Quen&#x000e9;</surname><given-names>H</given-names></name>, <name><surname>van den Bergh</surname><given-names>H</given-names></name>. <article-title>On multi-level modeling of data from repeated measures designs: a tutorial</article-title>. <source>Speech Commun</source>. <year>2004</year>;<volume>43</volume>(<issue>1&#x02013;2</issue>): <fpage>103</fpage>&#x02013;<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.specom.2004.02.004">10.1016/j.specom.2004.02.004</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Judd</surname><given-names>CM</given-names></name>, <name><surname>Westfall</surname><given-names>J</given-names></name>, <name><surname>Kenny</surname><given-names>D a</given-names></name>. <article-title>Treating stimuli as a random factor in social psychology: A new and comprehensive solution to a pervasive but largely ignored problem</article-title>. <source>J Pers Soc Psychol</source>. <year>2012</year>;<volume>103</volume>(<issue>1</issue>): <fpage>54</fpage>&#x02013;<lpage>69</lpage>. <pub-id pub-id-type="pmid">22612667</pub-id></mixed-citation></ref><ref id="pone.0153712.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Ravaja</surname><given-names>N</given-names></name>, <name><surname>Saari</surname><given-names>T</given-names></name>, <name><surname>Kallinen</surname><given-names>K</given-names></name>, <name><surname>Laarni</surname><given-names>J</given-names></name>. <article-title>The role of mood in the processing of media messages from a small screen: Effects on subjective and physiological responses</article-title>. <source>Media Psychol</source>. <year>2006</year>;<volume>8</volume>(<issue>3</issue>): <fpage>239</fpage>&#x02013;<lpage>65</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1207/s1532785xmep0803_3">10.1207/s1532785xmep0803_3</ext-link></comment></mixed-citation></ref><ref id="pone.0153712.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Berntson</surname><given-names>GG</given-names></name>, <name><surname>Bigger</surname><given-names>TJ</given-names></name>, <name><surname>Eckberg</surname><given-names>DL</given-names></name>, <name><surname>Grossman</surname><given-names>P</given-names></name>, <name><surname>Kaufmann</surname><given-names>PG</given-names></name>, <name><surname>Malik</surname><given-names>M</given-names></name>, <etal>et al</etal>
<article-title>Heart rate variability: Origins, methods, and interpretive caveats</article-title>. <source>Psychophysiology</source>. <year>1997</year>;<volume>34</volume>(<issue>6</issue>): <fpage>623</fpage>&#x02013;<lpage>48</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1542-474X.1996.tb00275.x">10.1111/j.1542-474X.1996.tb00275.x</ext-link></comment>
<pub-id pub-id-type="pmid">9401419</pub-id></mixed-citation></ref><ref id="pone.0153712.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Slovic</surname><given-names>P</given-names></name>, <name><surname>Finucane</surname><given-names>ML</given-names></name>, <name><surname>Peters</surname><given-names>E</given-names></name>, <name><surname>MacGregor</surname><given-names>DG</given-names></name>. <article-title>The affect heuristic</article-title>. <source>Eur J Oper Res</source>. <year>2007</year>;<volume>177</volume>(<issue>3</issue>): <fpage>1333</fpage>&#x02013;<lpage>52</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.4135/9781412956253.n9">10.4135/9781412956253.n9</ext-link></comment></mixed-citation></ref></ref-list></back></article>